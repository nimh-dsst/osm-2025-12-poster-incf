# XML Metadata Extraction Tools
**Document created:** 2025-11-06

Python scripts tools for extracting metadata from PubMed Central (PMC) XML files.
Both code and documentation was written using Claude code and have not yet been carefully reviewed.
Supports both direct file processing and streaming extraction from tar.gz archives.

## Overview

This toolkit provides two complementary extraction methods:

| Tool | Speed | Input | Best For |
|------|-------|-------|----------|
| **Streaming Extractor** | 1,125 files/sec | tar.gz archives | Bulk processing, production |
| **File-Based Extractor** | 229 files/sec | XML files/directories | Selective processing, development |

Both tools extract identical metadata into a 122-column format suitable for research transparency analysis.

## Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd rtransparent_sif_output

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

**For tar.gz archives (recommended):**
```bash
python extract_from_tarballs.py --format parquet -o output.parquet /path/to/archives/
```

**For XML files:**
```bash
python extract_xml_metadata.py --format parquet -o output.parquet /path/to/xmls/
```

## Features

- âœ… **Fast Processing:** 1,125 files/second (streaming mode)
- âœ… **Zero Disk Footprint:** No intermediate files needed
- âœ… **Flexible Input:** tar.gz archives or XML files
- âœ… **Multiple Formats:** CSV or Parquet output
- âœ… **Production Ready:** Comprehensive error handling
- âœ… **Well Documented:** Extensive guides and examples

## Tools

### 1. Streaming Extractor (`extract_from_tarballs.py`)

Processes tar.gz archives directly without extracting files to disk.

**Performance:** 1,125 files/second | **Speedup:** 5x faster than file-based

```bash
# Process all archives
python extract_from_tarballs.py /path/to/archives/

# With options
python extract_from_tarballs.py \
    --format parquet \
    --output results.parquet \
    --pattern "*.baseline.*" \
    /path/to/archives/
```

ðŸ“– **[Full Documentation](README_STREAMING.md)**

### 2. File-Based Extractor (`extract_xml_metadata.py`)

Processes individual XML files or directories.

**Performance:** 229 files/second | **Use Case:** Selective reprocessing

```bash
# Process directory
python extract_xml_metadata.py /path/to/xmls/

# Process specific files
python extract_xml_metadata.py file1.xml file2.xml -o output.csv
```

ðŸ“– **[Full Documentation](README_EXTRACTOR.md)**

## Documentation

- **[README_STREAMING.md](README_STREAMING.md)** - Streaming extractor guide
- **[README_EXTRACTOR.md](README_EXTRACTOR.md)** - File-based extractor guide
- **[TOOLS_COMPARISON.md](TOOLS_COMPARISON.md)** - Detailed comparison and use cases
- **[BENCHMARK_REPORT.md](BENCHMARK_REPORT.md)** - Performance analysis
- **[data_dictionary.csv](data_dictionary.csv)** - Complete column definitions

## Output Format

Both tools produce identical output with **122 columns**:

- **18 "copied" columns:** Metadata extracted directly from XML
  - Identifiers: pmid, pmcid_pmc, doi
  - Journal info: journal, publisher, year_epub, year_ppub
  - Funding: fund_pmc_institute, fund_pmc_source
  - Text fields: coi_text, fund_text, register_text
  - And more...

- **102 "sophisticated" columns:** Left empty for NLP/pattern matching
  - COI patterns (29 columns)
  - Funding patterns (45 columns)
  - Registration patterns (23 columns)
  - Open science indicators (5 columns)

- **2 metric columns:** file_size, chars_in_body

See [data_dictionary.csv](data_dictionary.csv) for complete column documentation.

## Performance

### Benchmark Results

**Streaming Extractor:**
- 1,125 files/second
- Process 100,000 files in ~1.5 minutes
- No temporary disk space required

**File-Based Extractor:**
- 229 files/second
- Process 100,000 files in ~7.3 minutes
- Requires files on disk

**Speedup:** 4.9x faster with streaming approach

See [BENCHMARK_REPORT.md](BENCHMARK_REPORT.md) for detailed analysis.

## Command Line Options

### Streaming Extractor

```bash
python extract_from_tarballs.py [options] <tar_directory>

Options:
  -o, --output FILE         Output file path
  -f, --format {csv,parquet} Output format (default: csv)
  --limit N                 Process only first N archives
  --pattern GLOB            Filter archives by pattern
```

### File-Based Extractor

```bash
python extract_xml_metadata.py [options] <paths...>

Options:
  -o, --output FILE         Output file path
  -f, --format {csv,parquet} Output format (default: csv)
```

## Use Cases

### Scenario 1: Initial Bulk Processing
**Situation:** Process tar.gz archives downloaded from PMCOA

**Solution:** Use streaming extractor
```bash
python extract_from_tarballs.py \
    --format parquet \
    -o pmc_full.parquet \
    /data/pmc_archives/
```
**Time:** ~2-3 minutes

### Scenario 2: Daily Incremental Updates
**Situation:** Process new daily tar.gz files

**Solution:** Use streaming extractor with pattern
```bash
python extract_from_tarballs.py \
    --pattern "*$(date +%Y-%m-%d)*" \
    --format parquet \
    -o daily_update.parquet \
    /data/pmc_archives/
```

### Scenario 3: Reprocess Specific Files
**Situation:** Fix errors in 50 specific articles

**Solution:** Use file-based extractor
```bash
python extract_xml_metadata.py \
    PMC*.xml \
    --format parquet \
    -o corrections.parquet
```

See [TOOLS_COMPARISON.md](TOOLS_COMPARISON.md) for more scenarios.

## Requirements

- Python 3.7+
- pandas >= 1.3.0
- pyarrow >= 6.0.0

## Installation

### Method 1: Using pip (recommended)

```bash
pip install -r requirements.txt
```

### Method 2: Using conda

```bash
conda create -n xml-extract python=3.9
conda activate xml-extract
conda install pandas pyarrow
```

### Verify Installation

```bash
python extract_xml_metadata.py --help
python extract_from_tarballs.py --help
```

## Platform Support

âœ… **Linux** - Should work, but not yet tested
âœ… **macOS** - Tested and validated
âœ… **Windows** - Not tested

## Testing

Validate the tools work on your platform:

```bash
# Test file-based extractor (requires sample XML)
python extract_xml_metadata.py sample.xml -o test.csv

# Test streaming extractor (requires sample tar.gz)
python extract_from_tarballs.py --limit 1 /path/to/archives/

# Verify output
python -c "import pandas as pd; print(pd.read_csv('test.csv').shape)"
```

## Data Sources

These tools are designed for:
- **PubMed Central Open Access** XML files (JATS format)
- **PMC Bulk Download** archives
- Any JATS-compliant XML files

**PMC Data:** https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/

---

**Quick Links:**
- [Streaming Extractor Documentation](README_STREAMING.md)
- [File-Based Extractor Documentation](README_EXTRACTOR.md)
- [Performance Comparison](TOOLS_COMPARISON.md)
- [Benchmark Report](BENCHMARK_REPORT.md)
- [Data Dictionary](data_dictionary.csv)
