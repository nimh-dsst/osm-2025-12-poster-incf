# Open Science Metrics - INCF 2025 Conference Poster

**Conference:** EBRAINS/INCF Conference
**Location:** Brussels, Belgium
**Date:** December 11, 2025
**Project:** Research transparency analysis from PubMed Central Open Access corpus

## Overview

This repository contains analysis code and tools for generating research transparency metrics presented at the INCF 2025 conference. The analysis examines ~6.5M biomedical research articles from PubMed Central Open Access to assess:

- Open data and code sharing practices
- Funding source attribution
- Conflict of interest declarations
- Trial registration compliance

## Repository Structure

```
osm-2025-12-poster-incf/
â”œâ”€â”€ extraction_tools/      # XML metadata extraction scripts
â”‚   â”œâ”€â”€ extract_xml_metadata.py
â”‚   â”œâ”€â”€ extract_from_tarballs.py
â”‚   â”œâ”€â”€ populate_metadata_iterative.py
â”‚   â””â”€â”€ merge_parquet_*.py
â”œâ”€â”€ funder_analysis/       # Funder mapping and analysis
â”‚   â”œâ”€â”€ funder-mapping-parquet.py
â”‚   â””â”€â”€ funder_mapping.py
â”œâ”€â”€ analysis/              # Poster analysis scripts
â”‚   â””â”€â”€ (analysis notebooks and scripts)
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ data_dictionary.csv
â”‚   â””â”€â”€ *.md
â””â”€â”€ results/               # Small summary files only
```

## Data Sources

**Input Data:**
- PubMed Central Open Access bulk XML files
- rtransparent R package output (120+ columns per article)
- Full parquet dataset: `rtrans_out_full_parquets/` (1,647 files, 1.8 GB)

**NOT Included in Repository:**
- Raw XML files (~150 GB)
- Large parquet files (see `.gitignore`)
- Intermediate processing files

Data available from:
- PMC OA: https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/
- rtransparent: https://github.com/nimh-dsst/rtransparent

## Requirements

### Python Dependencies

```bash
# Create virtual environment (optional but recommended)
python3 -m venv venv
source venv/bin/activate

# Install required packages
pip install -r requirements.txt

# For Jupyter notebooks and additional tools
pip install -r requirements-dev.txt
```

Core packages: pandas, numpy, pyarrow, matplotlib

### Data Access

Analysis scripts expect access to:
- PMC XML files: https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/
- rtransparent output: `~/pmcoaXMLs/rtrans_out_full_parquets/` (1,647 files)

## Quick Start

### 1. Extract Metadata from PMC Archives

```bash
cd extraction_tools
source venv/bin/activate

# Stream from tar.gz archives (fast, recommended)
python extract_from_tarballs.py \
  -f parquet \
  -o baseline_metadata.parquet \
  /path/to/pmc/archives/
```

### 2. Process with rtransparent (HPC)

Use the rtransparent R package to analyze XMLs and generate full parquet outputs.

### 3. Map Funding Sources

```bash
cd funder_analysis
source venv/bin/activate

python funder-mapping-parquet.py \
  --input /path/to/rtrans_out_full_parquets/ \
  --output funder_results/
```

### 4. Generate Poster Analyses

```bash
cd analysis
# Run analysis notebooks or scripts
jupyter notebook
```

## Data Schema

**Complete dataset:** 122 columns
- **Identifiers:** pmid, pmcid, doi
- **Metadata:** journal, publisher, year, country
- **COI Detection:** 29 pattern columns
- **Funding:** 45 pattern columns + funder array
- **Registration:** 23 pattern columns
- **Open Science:** is_open_data, is_open_code

See `docs/data_dictionary.csv` for complete documentation.

## Branches

- **main**: Stable, production-ready code for poster
- **develop**: Active development branch

## Migration History

This repository consolidates analysis code from:
- `rtransparent` repo (branch: `feature/extract-XML-metadata`)
- `osm` repo (branch: `agt-funder-matrix`)

Migration completed: 2025-11-24

## Important Notes

âš ï¸ **Data Files:**
- Never commit large data files (XMLs, parquets, tar.gz)
- Use `.gitignore` to prevent accidental commits
- Small summary CSVs/markdown files (<10 MB) are acceptable

ğŸ“Š **Performance:**
- Streaming extraction: ~1,125 files/sec
- Full dataset processing: ~5-10 minutes (metadata extraction)
- Memory requirements: ~4-8 GB RAM for batch processing

## Documentation

- `docs/REORGANIZATION_PLAN.md` - Project restructuring documentation
- `docs/is_open_data_missing_analysis.md` - Data quality analysis
- `docs/BENCHMARK_REPORT.md` - Performance benchmarks
- `docs/TOOLS_COMPARISON.md` - Tool selection guide

## Contact

For questions about this analysis, contact the NIMH Data Science and Sharing Team.

## License

TBD
